---
title: "A Little Taste of Linguistics in MT"
tags: [Machine Translation, Morphology]
---
In coursework 3, we are allowed to choose a language which there are no published MT results as our "research language". As for the research problem, my teammate and I decided to study sth about how to improve the BLEU score of a Inuktitut to English NMT model(3 layer bidirectional LSTM).

It's never hard to implement a vanilla LSTM model via DL/ML framework, like tensorflow, chainer, etc. And it's never a problem to implement the algorithm decribed in those crazy papers. What made me stuck and struggle for so long is the linguitic knowledge, to be precise, the morphology, of the Inuktitut.

First of all, we need to understand why there are no published NMT results. It's not just because there are less than 100,000 people speaking Inuktiut, but the language itself is complcated. Inuktitut is a so-called "polysynthetic" language. 

It took us a few days to figure out what exactly "polysynthetic" means. At the very first begining, we only had one question, what is "polysynthetic". Then when we were investigating, the questions kept piling up like a snowball rolling down a hill...

When I directly googled the word "polysynthetic" and read the explaination in wikipage, I was totally lost. As posted in the [wikipage](https://en.wikipedia.org/wiki/Polysynthetic_language):

> "...polysynthetic languages are highly synthetic languages, i.e. languages in which words are composed of many morphemes ...

Ok, Inuktitut is "highly synthetic", and its words are composed of many "morphemes". But what does "highly synthetic" and "morpheme" mean? Then I googles these term again, and I got something like:

> "... a morpheme is the smallest grammatical unit in a language. ...The field of study dedicated to morphemes is called morphology. ..." (From wikipage, [Morpheme](https://en.wikipedia.org/wiki/Morpheme))

Well, "the smallest grammatical unit", and "morphology". The latter sound fancy, maybe I should google...NO, STOP! 

Machine learning is far more difficult than I thought. Anyway, the coursework 3 is done, and now I  finally understand those fancy terminlogies  like "analytic/isolating", "agglutinative", "fusional", blahblah...

## personal notes: Morphological Typology
### morpheme
Morphemes are kind of like words, but simpler. Each morpheme only contains one meaning. For example, "coursework" is a **word**, and it has two **morpheme**, "course" and "work". That's all.



### Analytic/Isolating Languages
Words of such languages only have one morpheme for each. The definition is very strict. It's not easy to find such languages which are perfectly "analytic". English is an example of analytic languages, so as Chinese. 

### Agglutinative Languages
More complexed than the previous one. There are more than one morpheme in one word. A new word can be generated by concatinaing a few morphemes. e.g., "course"+"work", "art"+"ist", 

### Fusional Languages
Similar to agglutinative, a word has more than one morphemes. The difference is, a morpheme can have multiple grammatical info. e.g.

+ Spanish 'abl-o, **o** means 1st person, single, present tense. 

Not only a morph can have multiple grammatical meanings, but one meaning can be shared among multiple morphs.

+ Latin re:ksisti -- you all ruled
"perfective" menaing is shared by s, is, ti

### Polysynthetic Languages
Maybe the hardest. Inuktitut might the extreme example. Inuktitut can be both fusional and agglutinative. They are much more morphs in one single word,  a single word can be translated in a long English sentence. 

+ qangatasuukkuvimmuuriaqalaaqtunga  I'll have to go to the airport.

### Synthetic Languages
the combination of agglu., fusional and polys.

That's all. These are the very basic background of **morphology typology**.  

## Inuktitut
The vanilla LSTM really cannot help translating Inuktitut into English. In the parallel corpus, the sentence length distributions of these two language are wildly different. Over 50% of  Inuktitut sentences have no more than 2 words. Sometimes a 50-word long Inuktitut sentence can be translated into a 100+-word long English sentence.

Therefore we came out of an idea to parse the Inuktitut. And it becomes  difficult again. There are so many strange stuffs like the rule to combine consonants and vowels into syllabics, the grammer, etc.

I'm gonna here, because it might take pages to explain those rules. 

To conclue, Neural Machine Translation is young and powerful, I used to believe that NMT is a math or probabilitic problem. Now I know that linguistics is also significant in this domain. That's actually fun to me, it's like the combination of Art and Science.


